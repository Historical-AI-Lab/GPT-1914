{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train classification model\n",
    "\n",
    "Trains and tests a random forest model on page data after dividing it by volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GroupKFold, cross_val_score, GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = pd.read_csv('featurematrix.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pagenum', 'pagefrac', 'backnum', 'backfrac', 'nlines', 'nwords',\n",
       "       'nalpha', 'fracalpha', 'nnumeric', 'fracnumeric', 'npunct', 'fracpunct',\n",
       "       'nupper', 'fracupper', 'nother', 'fracother', 'meanlinelen',\n",
       "       'sdlinelen', 'meanwordlength', 'startupper', 'top20words',\n",
       "       'top2000words', 'paratextwords', 'label', 'nwordsminusmean',\n",
       "       'wordlengthminusmean', 'linelenminusmean', 'top2000minusmean',\n",
       "       'nwordsminusprev', 'top2000minusprev', 'centerdist', 'centerdist^2',\n",
       "       'pagefrac^2', 'backfrac^2', 'htid'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique htids in pages\n",
    "unique_htids = pages['htid'].unique().tolist()\n",
    "\n",
    "# Calculate the number of htids for training and testing\n",
    "num_train_htids = int(len(unique_htids) * 0.8)\n",
    "num_test_htids = len(unique_htids) - num_train_htids\n",
    "\n",
    "# Randomly select htids for training and testing\n",
    "train_htids = np.random.choice(unique_htids, size=num_train_htids, replace=False)\n",
    "test_htids = list(set(unique_htids) - set(train_htids))\n",
    "\n",
    "# Divide the pages dataframe into pages_train and pages_test\n",
    "pages_train = pages[pages['htid'].isin(train_htids)]\n",
    "pages_test = pages[pages['htid'].isin(test_htids)]\n",
    "\n",
    "# Delete the original pages dataframe\n",
    "del pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = pages_train['label']\n",
    "pages_train = pages_train.drop('label', axis=1)\n",
    "htids_train = pages_train['htid']\n",
    "pages_train = pages_train.drop('htid', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Best cross-validation score: 0.9850203960968479\n"
     ]
    }
   ],
   "source": [
    "# Create the RandomForestClassifier\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [200, 300],\n",
    "    'max_depth': [None, 40],\n",
    "    'min_samples_split': [2, 3]\n",
    "}\n",
    "\n",
    "# Create the GroupKFold object\n",
    "group_kfold = GroupKFold(n_splits=5)\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=group_kfold, n_jobs=-1)\n",
    "\n",
    "# Perform grid search with grouped cross-validation\n",
    "grid_search.fit(pages_train, labels_train, groups=htids_train)\n",
    "\n",
    "print(\"Best parameters found:\", grid_search.best_params_)\n",
    "print(\"Best cross-validation score:\", grid_search.best_score_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "global312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
