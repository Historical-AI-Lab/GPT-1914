{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Qual Fine-Tuning Data\n",
    "\n",
    "We have fine-tuning data in JSON, but it isn't in the right format and contains unnecessary fields. This puts it in the right format for submission to OAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import textwrap\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/tunder/Library/CloudStorage/Dropbox/python/GPT-1914/anachronism/qualitative'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('clean_questions.json') as f:\n",
    "    questions = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are producing a simulation of early twentieth-century print\n",
      "culture. Respond to all questions and instructions as if you were\n",
      "living in early 1914, using only knowledge written down or believed at\n",
      "the time. If you're asked about a person, event, or idea that wouldn't\n",
      "have been discussed in print in 1914, explain that you're unfamiliar\n",
      "with the term.\n",
      "\n",
      "You may be asked to complete stories. The proper names of some\n",
      "characters may be changed, but that's not important; you'll recognize\n",
      "the plots. If you are asked to complete a story that was published\n",
      "before 1914, complete it as originally written. If the story was\n",
      "published after 1914, you would be unfamiliar with it, so you must\n",
      "invent a different set of events that could complete the story--\n",
      "without echoing any story published after 1914.\n",
      "\n",
      "Some ideas and terms that are now unacceptable would have been normal\n",
      "in the early twentieth century.  So let yourself be guided by the\n",
      "language and attitudes of the time. Also, since this is meant to be a\n",
      "realistic simulation, avoid self-conscious remarks that give away your\n",
      "later perspective--like, \"Here in 1914, we still believe that ...\"\n",
      "Simply respond as if you were living in the early twentieth century.\n"
     ]
    }
   ],
   "source": [
    "def print_wrapped_text(text, width=70):\n",
    "    texts = text.split('\\n')\n",
    "    if len(texts) > 1:\n",
    "        for t in texts:\n",
    "            print_wrapped_text(t, width=70)\n",
    "\n",
    "    else:\n",
    "        text = texts[0]\n",
    "        wrapper = textwrap.TextWrapper(width=width)\n",
    "        wrapped_text = wrapper.fill(text)\n",
    "        print(wrapped_text)\n",
    "\n",
    "system_prompt = '''You are producing a simulation of early twentieth-century print culture.\n",
    "Respond to all questions and instructions as if you were living in early 1914, using\n",
    "only knowledge written down or believed at the time. If you're asked about a person, event, or idea that wouldn't have been discussed in print in 1914,\n",
    "explain that you're unfamiliar with the term. \n",
    "\n",
    "You may be asked to complete stories. The proper names of some characters\n",
    "may be changed, but that's not important; you'll recognize the plots.\n",
    "If you are asked to complete a story that was published before 1914, complete it as originally written.\n",
    "If the story was published after 1914, you would be unfamiliar with it, so\n",
    "you must invent a different set of events that could complete the story--\n",
    "without echoing any story published after 1914.\n",
    "\n",
    "Some ideas and terms that are now unacceptable would have been normal in the early twentieth century. \n",
    "So let yourself be guided by the language and attitudes of the time. Also, since this\n",
    "is meant to be a realistic simulation, avoid self-conscious remarks that give away\n",
    "your later perspective--like, \"Here in 1914, we still believe that ...\" Simply\n",
    "respond as if you were living in the early twentieth century. \n",
    "'''\n",
    "\n",
    "system_prompt = system_prompt.replace('\\n\\n', '\\t').replace('\\n', ' ').replace('\\t', '\\n\\n')\n",
    "print_wrapped_text(system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We divide into train and validation sets based on the subj fields, so first we need \n",
    "# to ensure that all questions have a subj field. If they don't, we assign them one.\n",
    "\n",
    "ctr = 0\n",
    "allsubjs = set()\n",
    "for q in questions:\n",
    "    if 'subj' in q:\n",
    "        allsubjs.add(q['subj'])\n",
    "        \n",
    "    else:\n",
    "        ctr += 1\n",
    "        q['subj'] = 'subj' + str(ctr)\n",
    "        allsubjs.add(q['subj'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_and_val_fold(train_subjs, validate_subjs, foldnum):\n",
    "    # We start by dividing questions into train and validate sets. We want to make sure that\n",
    "    # all questions about a particular subject are in the same set.\n",
    "    global questions\n",
    "\n",
    "    train = []\n",
    "    validate = []\n",
    "    fictions = ['frozen', 'hobbit', 'hungergames', 'starwars', 'wharton']\n",
    "    for i in range(5):\n",
    "        if i != foldnum:\n",
    "            train_subjs.add(fictions[i])\n",
    "        else:\n",
    "            validate_subjs.add(fictions[foldnum])\n",
    "\n",
    "    # We iterate through questions putting each into train with probability\n",
    "    # 80% and into validate with probability 20%. However, if the subj field\n",
    "    # is already in train_subjs, we automatically put it into train.\n",
    "\n",
    "    target_proportion = 0.8\n",
    "\n",
    "    # Since this will create a slight imbalance in the number of questions,\n",
    "    # we dynamically adjust the probability of putting a question into train\n",
    "    # based on the number of questions already in train.\n",
    "\n",
    "    for q in questions:\n",
    "        if q['subj'] in train_subjs:\n",
    "            train.append(q)\n",
    "        elif q['subj'] in validate_subjs:\n",
    "            validate.append(q)\n",
    "        else:\n",
    "            if random.random() < target_proportion:\n",
    "                train.append(q)\n",
    "                train_subjs.add(q['subj'])\n",
    "            else:\n",
    "                validate.append(q)\n",
    "                validate_subjs.add(q['subj'])\n",
    "        balance = (len(train) + 1) / (len(train) + len(validate) + 2)\n",
    "        if foldnum == 4:\n",
    "            target_proportion = 0 # we want to fill the last fold with all the remaining questions\n",
    "        elif len(validate) > 55:\n",
    "            target_proportion = 1 # the validate set is full!\n",
    "        elif balance < 0.784:\n",
    "            target_proportion = 0.784 + (0.785 - balance)\n",
    "        else:\n",
    "            target_proportion = 0.784 - (balance - 0.785) * 6\n",
    "\n",
    "    print(f'Train set has {len(train)} questions.')\n",
    "    print(f'Validate set has {len(validate)} questions.')\n",
    "    print(f'Balance is {balance}.')\n",
    "\n",
    "    formatted_train = []\n",
    "    formatted_validate = []\n",
    "\n",
    "    # we need to put the system prompt, user, and assistant in this format:\n",
    "    # {\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What's the capital of France?\"}, {\"role\": \"assistant\", \"content\": \"Paris, as if everyone doesn't know that already.\"}]}\n",
    "    # However, there may be multiple user and assistant messages in a row, and they\n",
    "    # need to alternate.\n",
    "    \n",
    "    for q in train:\n",
    "        message = {\"messages\": [{\"role\": \"system\", \"content\": system_prompt}]}\n",
    "        assert len(q['user']) == len(q['assistant'])\n",
    "        turns = len(q['user'])\n",
    "        for i in range(turns):\n",
    "            user_segment = q['user'][i]\n",
    "            assistant_segment = q['assistant'][i]\n",
    "            message[\"messages\"].append({\"role\": \"user\", \"content\": user_segment})\n",
    "            message[\"messages\"].append({\"role\": \"assistant\", \"content\": assistant_segment})\n",
    "        formatted_train.append(message)\n",
    "\n",
    "    for q in validate:\n",
    "        message = {\"messages\": [{\"role\": \"system\", \"content\": system_prompt}]}\n",
    "        assert len(q['user']) == len(q['assistant'])\n",
    "        turns = len(q['user'])\n",
    "        for i in range(turns):\n",
    "            user_segment = q['user'][i]\n",
    "            assistant_segment = q['assistant'][i]\n",
    "            message[\"messages\"].append({\"role\": \"user\", \"content\": user_segment})\n",
    "            message[\"messages\"].append({\"role\": \"assistant\", \"content\": assistant_segment})\n",
    "        formatted_validate.append(message)\n",
    "    \n",
    "    return formatted_train, formatted_validate, validate_subjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'atoms',\n",
       " 'cholera',\n",
       " 'churchill',\n",
       " 'ethnology',\n",
       " 'eugenics',\n",
       " 'fitzgerald',\n",
       " 'fossils',\n",
       " 'frozen',\n",
       " 'goblinmarket',\n",
       " 'hobbit',\n",
       " 'hungergames',\n",
       " 'indochina',\n",
       " 'radio',\n",
       " 'sinojapanese',\n",
       " 'starwars',\n",
       " 'subj1',\n",
       " 'subj10',\n",
       " 'subj100',\n",
       " 'subj101',\n",
       " 'subj102',\n",
       " 'subj103',\n",
       " 'subj104',\n",
       " 'subj105',\n",
       " 'subj106',\n",
       " 'subj107',\n",
       " 'subj108',\n",
       " 'subj109',\n",
       " 'subj11',\n",
       " 'subj110',\n",
       " 'subj111',\n",
       " 'subj112',\n",
       " 'subj113',\n",
       " 'subj114',\n",
       " 'subj115',\n",
       " 'subj116',\n",
       " 'subj117',\n",
       " 'subj118',\n",
       " 'subj119',\n",
       " 'subj12',\n",
       " 'subj120',\n",
       " 'subj121',\n",
       " 'subj122',\n",
       " 'subj123',\n",
       " 'subj124',\n",
       " 'subj125',\n",
       " 'subj126',\n",
       " 'subj127',\n",
       " 'subj128',\n",
       " 'subj129',\n",
       " 'subj13',\n",
       " 'subj130',\n",
       " 'subj131',\n",
       " 'subj132',\n",
       " 'subj133',\n",
       " 'subj134',\n",
       " 'subj135',\n",
       " 'subj136',\n",
       " 'subj137',\n",
       " 'subj138',\n",
       " 'subj139',\n",
       " 'subj14',\n",
       " 'subj140',\n",
       " 'subj141',\n",
       " 'subj142',\n",
       " 'subj143',\n",
       " 'subj144',\n",
       " 'subj145',\n",
       " 'subj146',\n",
       " 'subj147',\n",
       " 'subj148',\n",
       " 'subj149',\n",
       " 'subj15',\n",
       " 'subj150',\n",
       " 'subj151',\n",
       " 'subj152',\n",
       " 'subj153',\n",
       " 'subj154',\n",
       " 'subj155',\n",
       " 'subj156',\n",
       " 'subj157',\n",
       " 'subj158',\n",
       " 'subj159',\n",
       " 'subj16',\n",
       " 'subj160',\n",
       " 'subj161',\n",
       " 'subj162',\n",
       " 'subj163',\n",
       " 'subj164',\n",
       " 'subj165',\n",
       " 'subj166',\n",
       " 'subj167',\n",
       " 'subj168',\n",
       " 'subj169',\n",
       " 'subj17',\n",
       " 'subj170',\n",
       " 'subj171',\n",
       " 'subj172',\n",
       " 'subj173',\n",
       " 'subj174',\n",
       " 'subj175',\n",
       " 'subj176',\n",
       " 'subj177',\n",
       " 'subj178',\n",
       " 'subj179',\n",
       " 'subj18',\n",
       " 'subj180',\n",
       " 'subj181',\n",
       " 'subj182',\n",
       " 'subj183',\n",
       " 'subj184',\n",
       " 'subj185',\n",
       " 'subj186',\n",
       " 'subj187',\n",
       " 'subj188',\n",
       " 'subj189',\n",
       " 'subj19',\n",
       " 'subj190',\n",
       " 'subj191',\n",
       " 'subj192',\n",
       " 'subj193',\n",
       " 'subj194',\n",
       " 'subj195',\n",
       " 'subj196',\n",
       " 'subj197',\n",
       " 'subj198',\n",
       " 'subj199',\n",
       " 'subj2',\n",
       " 'subj20',\n",
       " 'subj200',\n",
       " 'subj201',\n",
       " 'subj202',\n",
       " 'subj203',\n",
       " 'subj204',\n",
       " 'subj205',\n",
       " 'subj206',\n",
       " 'subj207',\n",
       " 'subj208',\n",
       " 'subj209',\n",
       " 'subj21',\n",
       " 'subj210',\n",
       " 'subj211',\n",
       " 'subj212',\n",
       " 'subj213',\n",
       " 'subj214',\n",
       " 'subj215',\n",
       " 'subj216',\n",
       " 'subj217',\n",
       " 'subj218',\n",
       " 'subj219',\n",
       " 'subj22',\n",
       " 'subj220',\n",
       " 'subj221',\n",
       " 'subj222',\n",
       " 'subj223',\n",
       " 'subj224',\n",
       " 'subj225',\n",
       " 'subj226',\n",
       " 'subj227',\n",
       " 'subj228',\n",
       " 'subj229',\n",
       " 'subj23',\n",
       " 'subj230',\n",
       " 'subj231',\n",
       " 'subj232',\n",
       " 'subj233',\n",
       " 'subj24',\n",
       " 'subj25',\n",
       " 'subj26',\n",
       " 'subj27',\n",
       " 'subj28',\n",
       " 'subj29',\n",
       " 'subj3',\n",
       " 'subj30',\n",
       " 'subj31',\n",
       " 'subj32',\n",
       " 'subj33',\n",
       " 'subj34',\n",
       " 'subj35',\n",
       " 'subj36',\n",
       " 'subj37',\n",
       " 'subj38',\n",
       " 'subj39',\n",
       " 'subj4',\n",
       " 'subj40',\n",
       " 'subj41',\n",
       " 'subj42',\n",
       " 'subj43',\n",
       " 'subj44',\n",
       " 'subj45',\n",
       " 'subj46',\n",
       " 'subj47',\n",
       " 'subj48',\n",
       " 'subj49',\n",
       " 'subj5',\n",
       " 'subj50',\n",
       " 'subj51',\n",
       " 'subj52',\n",
       " 'subj53',\n",
       " 'subj54',\n",
       " 'subj55',\n",
       " 'subj56',\n",
       " 'subj57',\n",
       " 'subj58',\n",
       " 'subj59',\n",
       " 'subj6',\n",
       " 'subj60',\n",
       " 'subj61',\n",
       " 'subj62',\n",
       " 'subj63',\n",
       " 'subj64',\n",
       " 'subj65',\n",
       " 'subj66',\n",
       " 'subj67',\n",
       " 'subj68',\n",
       " 'subj69',\n",
       " 'subj7',\n",
       " 'subj70',\n",
       " 'subj71',\n",
       " 'subj72',\n",
       " 'subj73',\n",
       " 'subj74',\n",
       " 'subj75',\n",
       " 'subj76',\n",
       " 'subj77',\n",
       " 'subj78',\n",
       " 'subj79',\n",
       " 'subj8',\n",
       " 'subj80',\n",
       " 'subj81',\n",
       " 'subj82',\n",
       " 'subj83',\n",
       " 'subj84',\n",
       " 'subj85',\n",
       " 'subj86',\n",
       " 'subj87',\n",
       " 'subj88',\n",
       " 'subj89',\n",
       " 'subj9',\n",
       " 'subj90',\n",
       " 'subj91',\n",
       " 'subj92',\n",
       " 'subj93',\n",
       " 'subj94',\n",
       " 'subj95',\n",
       " 'subj96',\n",
       " 'subj97',\n",
       " 'subj98',\n",
       " 'subj99',\n",
       " 'tarzan',\n",
       " 'wharton'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allsubjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set has 209 questions.\n",
      "Validate set has 56 questions.\n",
      "Balance is 0.7865168539325843.\n",
      "Wrote train_0.jsonl and val_0.jsonl\n",
      "Length of validate_subjs: 53\n",
      "Validate subjs: {'subj94', 'cholera', 'subj220', 'subj222', 'subj92', 'subj61', 'subj190', 'subj128', 'subj50', 'subj75', 'subj18', 'subj179', 'subj224', 'subj37', 'subj49', 'subj169', 'subj207', 'subj232', 'subj122', 'subj136', 'subj22', 'subj38', 'subj135', 'subj102', 'subj140', 'subj31', 'subj172', 'subj173', 'subj211', 'subj213', 'subj93', 'subj82', 'subj97', 'subj120', 'subj229', 'subj64', 'subj155', 'subj14', 'subj15', 'subj6', 'subj185', 'frozen', 'subj73', 'subj88', 'subj161', 'subj27', 'subj137', 'subj32', 'subj163', 'subj76', 'subj175', 'subj192', 'subj104'}\n",
      "53\n",
      "Train set has 213 questions.\n",
      "Validate set has 52 questions.\n",
      "Balance is 0.8014981273408239.\n",
      "Wrote train_1.jsonl and val_1.jsonl\n",
      "Length of validate_subjs: 50\n",
      "Validate subjs: {'subj42', 'subj5', 'subj149', 'subj159', 'subj126', 'subj60', 'subj101', 'subj43', 'subj3', 'subj99', 'subj125', 'subj164', 'subj57', 'subj39', 'subj58', 'subj68', 'subj98', 'subj109', 'subj221', 'eugenics', 'subj34', 'subj141', 'hobbit', 'subj156', 'subj52', 'subj188', 'subj217', 'subj219', 'subj171', 'subj47', 'subj21', 'subj56', 'radio', 'subj157', 'subj116', 'subj66', 'subj9', 'subj62', 'subj74', 'subj203', 'subj77', 'subj195', 'subj206', 'subj53', 'subj184', 'subj79', 'subj124', 'subj166', 'subj7', 'subj197'}\n",
      "103\n",
      "Train set has 215 questions.\n",
      "Validate set has 50 questions.\n",
      "Balance is 0.8089887640449438.\n",
      "Wrote train_2.jsonl and val_2.jsonl\n",
      "Length of validate_subjs: 45\n",
      "Validate subjs: {'subj95', 'subj223', 'subj233', 'subj86', 'subj194', 'subj72', 'subj33', 'subj121', 'subj118', 'subj168', 'sinojapanese', 'subj186', 'subj230', 'hungergames', 'subj170', 'subj167', 'subj227', 'subj150', 'subj45', 'subj182', 'subj103', 'subj114', 'subj153', 'subj90', 'subj228', 'subj46', 'subj178', 'subj209', 'subj71', 'subj111', 'subj231', 'subj13', 'subj84', 'subj144', 'subj145', 'subj40', 'fitzgerald', 'subj174', 'subj29', 'indochina', 'subj54', 'subj10', 'subj85', 'subj63', 'subj143'}\n",
      "148\n",
      "Train set has 217 questions.\n",
      "Validate set has 48 questions.\n",
      "Balance is 0.8164794007490637.\n",
      "Wrote train_3.jsonl and val_3.jsonl\n",
      "Length of validate_subjs: 46\n",
      "Validate subjs: {'starwars', 'subj202', 'subj215', 'subj44', 'subj65', 'subj96', 'subj205', 'subj100', 'subj12', 'subj119', 'subj154', 'subj199', 'subj30', 'subj55', 'subj139', 'subj133', 'goblinmarket', 'subj204', 'churchill', 'subj19', 'subj110', 'subj189', 'subj11', 'subj105', 'subj134', 'subj89', 'subj83', 'subj225', 'subj142', 'subj67', 'subj146', 'subj48', 'subj106', 'subj112', 'subj210', 'tarzan', 'subj80', 'subj148', 'subj69', 'subj160', 'subj130', 'subj59', 'subj187', 'subj17', 'subj180', 'subj147'}\n",
      "194\n",
      "Train set has 207 questions.\n",
      "Validate set has 58 questions.\n",
      "Balance is 0.7790262172284644.\n",
      "Wrote train_4.jsonl and val_4.jsonl\n",
      "Length of validate_subjs: 55\n",
      "Validate subjs: {'subj115', 'subj51', 'subj191', 'subj28', 'subj117', 'subj218', 'subj4', 'subj113', 'atoms', 'subj138', 'subj91', 'subj165', 'subj70', 'subj2', 'subj181', 'subj107', 'subj24', 'subj23', 'subj132', 'subj162', 'subj152', 'subj198', 'subj78', 'subj25', 'subj226', 'subj16', 'subj176', 'subj87', 'subj151', 'subj35', 'subj201', 'subj214', 'subj127', 'fossils', 'subj200', 'subj216', 'ethnology', 'subj20', 'subj129', 'subj177', 'wharton', 'subj41', 'subj8', 'subj36', 'subj26', 'subj108', 'subj158', 'subj131', 'subj123', 'subj81', 'subj193', 'subj183', 'subj208', 'subj212', 'subj196'}\n",
      "249\n"
     ]
    }
   ],
   "source": [
    "def write_jsonl(filename, jsonlist):\n",
    "    with open(filename, 'w') as f:\n",
    "        for j in jsonlist:\n",
    "            f.write(json.dumps(j) + '\\n')\n",
    "\n",
    "train_subjs = set()\n",
    "validate_subjs = set()\n",
    "used_validates = set()\n",
    "\n",
    "for i in range(5):\n",
    "\n",
    "    train, val, validate_subjs = get_train_and_val_fold(train_subjs, validate_subjs, i)\n",
    "\n",
    "    train_outfile = 'train_'+str(i) + '.jsonl'\n",
    "    val_outfile = f'val_{i}.jsonl'\n",
    "    write_jsonl(train_outfile, train)\n",
    "    write_jsonl(val_outfile, val)\n",
    "\n",
    "    print(f'Wrote train_{i}.jsonl and val_{i}.jsonl')\n",
    "    print(f'Length of validate_subjs: {len(validate_subjs)}')\n",
    "    for s in validate_subjs:\n",
    "        used_validates.add(s)\n",
    "    print(f'Validate subjs: {validate_subjs}')\n",
    "\n",
    "    validate_subjs = set()\n",
    "    train_subjs = set(used_validates)\n",
    "    print(len(train_subjs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('orig_format_val1.json', mode = 'w') as f:\n",
    "    json.dump(validate, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
